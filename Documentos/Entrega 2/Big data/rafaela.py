# -*- coding: utf-8 -*-
"""Rafaela.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12-VDCK9lPvnlLIKiFClaC77LoNo7btOm
"""

# === ETAPA 1: PREPARAR OS DADOS (InovaTech) ===
# Respons√°vel: Equipe InovaTech

import pandas as pd
import numpy as np


df_raw = pd.read_csv('merge_final.csv', sep=';', dtype=str, engine='python')

print(" Dataset carregado com sucesso!")
print(f"Total de registros: {len(df_raw)}")
print(f"Total de colunas: {len(df_raw.columns)}\n")

print(" Lista de colunas (primeiras 15):")
print(df_raw.columns[:15].tolist())
print("\nExemplo de dados brutos:")
display(df_raw.head(5))

missing = df_raw.isnull().sum().sort_values(ascending=False)
print("\n Top 10 colunas com mais valores ausentes:")
print(missing.head(10))


print("\n Tipos de dados originais:")
print(df_raw.dtypes.head(10))


df_raw.to_csv('merge_final_raw_backup.csv', index=False)
print("\n Arquivo bruto salvo: merge_final_raw_backup.csv")

print("""
 Observa√ß√µes InovaTech:
- O dataset cont√©m m√∫ltiplas entidades (clientes, pedidos, campanhas).
- A separa√ß√£o por ponto e v√≠rgula (';') foi confirmada.
- H√° colunas com alto volume de nulos (ex: descri√ß√µes, campos de integra√ß√£o).
- Essa vis√£o bruta ser√° usada como base para construir o pipeline de dados.
""")

# === ETAPA 2: SELECIONAR OS DADOS (InovaTech) ===
# Respons√°vel: Equipe InovaTech

import pandas as pd


df_raw = pd.read_csv('merge_final.csv', sep=';', dtype=str, engine='python')

print("Dataset original carregado com sucesso!")
print("Total de colunas originais:", len(df_raw.columns))


colunas_chave = [

    'id', 'storeId', 'companyId', 'customerId',


    'createdAt', 'updatedAt', 'scheduledAt', 'sendAt', 'dateOfBirth',


    'totalAmount', 'preparationTime', 'takeOutTimeInSeconds',


    'name', 'gender', 'phone', 'email', 'status'
]

colunas_presentes = [c for c in colunas_chave if c in df_raw.columns]
df_selected = df_raw[colunas_presentes].copy()

print(f"\n {len(colunas_presentes)} colunas selecionadas com sucesso:")
print(colunas_presentes)


print("\n Dimens√£o do dataset ap√≥s a sele√ß√£o:", df_selected.shape)
print("\nExemplo das primeiras linhas:")
display(df_selected.head(5))


print("\n Valores ausentes (Top 10 colunas):")
print(df_selected.isna().sum().sort_values(ascending=False).head(10))


df_selected.to_csv('merge_inovatech_selected.csv', index=False)
print("\n Arquivo gerado: merge_inovatech_selected.csv")


print("""
üìä Observa√ß√µes InovaTech:
- Selecionamos apenas colunas com valor anal√≠tico e de neg√≥cio.
- As colunas de cliente (nome, g√™nero, email) ser√£o √∫teis para perfis e segmenta√ß√µes.
- As colunas de tempo e valor apoiar√£o KPIs como tempo m√©dio de preparo e ticket m√©dio.
- Datas ser√£o usadas para an√°lises temporais (tend√™ncia, volume di√°rio, sazonalidade).
""")

# === ETAPA 3: LIMPAR / UNIFORMIZAR OS DADOS (InovaTech) ===
# Respons√°vel: Equipe InovaTech

import pandas as pd
import numpy as np


try:
    df_selected = pd.read_csv('merge_inovatech_selected.csv', sep=',', dtype=str)
except:
    df_selected = pd.read_csv('merge_final.csv', sep=';', dtype=str, engine='python')

print(" Dataset selecionado carregado:", df_selected.shape)


def to_snake_case(name):
    name = name.strip().replace(" ", "_").replace("-", "_").replace(".", "_")

    result = ""
    for ch in name:
        if ch.isupper():
            result += "_" + ch.lower()
        else:
            result += ch
    return result.strip("_")

df_clean = df_selected.copy()
df_clean.columns = [to_snake_case(c) for c in df_clean.columns]

print("\n Nomes de colunas padronizados com sucesso!")
print(df_clean.columns.tolist())

for col in df_clean.columns:
    df_clean[col] = df_clean[col].astype(str).str.strip().replace({
        "nan": np.nan,
        "None": np.nan,
        "": np.nan
    })


if "id" in df_clean.columns:
    registros_antes = len(df_clean)
    df_clean = df_clean.drop_duplicates(subset=["id"])
    print(f"\n Duplicatas removidas: {registros_antes - len(df_clean)} registros duplicados exclu√≠dos.")
else:
    df_clean = df_clean.drop_duplicates()

date_cols = [c for c in df_clean.columns if c.endswith("_at") or "date" in c]
for c in date_cols:
    df_clean[c] = pd.to_datetime(df_clean[c], errors="coerce")

print("\n Colunas de data convertidas:")
print(date_cols)


numeric_cols = ["total_amount", "preparation_time", "take_out_time_in_seconds"]
for c in numeric_cols:
    if c in df_clean.columns:
        df_clean[c] = (
            df_clean[c]
            .astype(str)
            .str.replace(".", "", regex=False)
            .str.replace(",", ".", regex=False)
        )
        df_clean[c] = pd.to_numeric(df_clean[c], errors="coerce").fillna(0)

print("\n Convers√£o num√©rica conclu√≠da nas colunas:")
print([c for c in numeric_cols if c in df_clean.columns])


fill_defaults = {
    "gender": "N√£o informado",
    "status": "Desconhecido"
}
df_clean = df_clean.fillna(value=fill_defaults)


print("\n Informa√ß√µes ap√≥s limpeza:")
print(df_clean.info())
print("\nTop 5 linhas do dataset limpo:")
display(df_clean.head())


df_clean.to_csv("merge_inovatech_clean.csv", index=False)
print("\n Arquivo gerado: merge_inovatech_clean.csv")


print("""
 Observa√ß√µes InovaTech:
- Todas as colunas seguem o padr√£o 'snake_case' (ex: total_amount, created_at).
- Datas foram convertidas para datetime (padr√£o ISO 8601).
- Valores ausentes e duplicados foram tratados.
- Colunas de g√™nero e status receberam preenchimentos padr√£o.
- Agora os dados est√£o padronizados e prontos para deriva√ß√£o.
""")

# === ETAPA 4: DERIVAR DADOS (InovaTech) ===
# Respons√°vel: Equipe InovaTech

import pandas as pd
import numpy as np

try:
    df_clean = pd.read_csv('merge_inovatech_clean.csv')
except:
    df_clean = pd.read_csv('merge_final.csv', sep=';', dtype=str, engine='python')

print(" Base carregada:", df_clean.shape)


df_clean.columns = [c.strip().lower().replace(" ", "_") for c in df_clean.columns]


df_deriv = df_clean.copy()

if {'preparation_time', 'take_out_time_in_seconds'}.issubset(df_deriv.columns):
    df_deriv['service_time_total'] = df_deriv['preparation_time'] + df_deriv['take_out_time_in_seconds']
    print(" Coluna criada: service_time_total (tempo total de atendimento em segundos)")

if 'total_amount' in df_deriv.columns:
    q1, q2 = df_deriv['total_amount'].quantile([0.33, 0.66])
    def categorizar_ticket(v):
        if pd.isna(v):
            return 'Desconhecido'
        elif v <= q1:
            return 'Baixo'
        elif v <= q2:
            return 'M√©dio'
        else:
            return 'Alto'
    df_deriv['ticket_categoria'] = df_deriv['total_amount'].apply(categorizar_ticket)
    print(" Coluna criada: ticket_categoria (faixa de valor do pedido)")

if 'date_of_birth' in df_deriv.columns:
    df_deriv['date_of_birth'] = pd.to_datetime(df_deriv['date_of_birth'], errors='coerce')
    hoje = pd.Timestamp.today().normalize()
    def calcular_idade(data):
        if pd.isna(data):
            return np.nan
        return int((hoje - data).days // 365.25)
    df_deriv['idade'] = df_deriv['date_of_birth'].apply(calcular_idade)
    print(" Coluna criada: idade (em anos)")

if {'total_amount', 'service_time_total'}.issubset(df_deriv.columns):
    df_deriv['valor_por_segundo'] = df_deriv['total_amount'] / df_deriv['service_time_total'].replace(0, np.nan)
    print(" Coluna criada: valor_por_segundo (efici√™ncia financeira do atendimento)")


print("\n Novas colunas derivadas:")
novas = [c for c in df_deriv.columns if c not in df_clean.columns]
print(novas)

display(df_deriv.head(10))


df_deriv.to_csv('merge_inovatech_derived.csv', index=False)
print("\n Arquivo gerado: merge_inovatech_derived.csv")

print("""
Observa√ß√µes InovaTech:
- Criamos m√©tricas estrat√©gicas que ajudam a entender desempenho operacional e financeiro.
- 'service_time_total' mede o tempo total de atendimento (preparo + retirada).
- 'ticket_categoria' agrupa pedidos por valor (baixo, m√©dio, alto), √≥timo para relat√≥rios de performance.
- 'idade' possibilita an√°lises demogr√°ficas de clientes.
- 'valor_por_segundo' √© um KPI que mostra quanto a opera√ß√£o gera por unidade de tempo.
""")

# === ETAPA 5: INTEGRAR OS DADOS ‚Äî InovaTech (Star Schema) ===
# Respons√°vel: Equipe InovaTech

import pandas as pd
import numpy as np

try:
    df_deriv = pd.read_csv('merge_inovatech_derived.csv')
    print("Base carregada: merge_inovatech_derived.csv")
except Exception:

    df_deriv = pd.read_csv('merge_final.csv', sep=';', dtype=str, engine='python')

    df_deriv.columns = [c.strip().lower().replace(" ", "_") for c in df_deriv.columns]
    for col in ['total_amount','preparation_time','take_out_time_in_seconds']:
        if col in df_deriv.columns:
            df_deriv[col] = (
                df_deriv[col].astype(str)
                              .str.replace('.', '', regex=False)
                              .str.replace(',', '.', regex=False)
            )
            df_deriv[col] = pd.to_numeric(df_deriv[col], errors='coerce').fillna(0)

    if {'preparation_time','take_out_time_in_seconds'}.issubset(df_deriv.columns):
        df_deriv['service_time_total'] = df_deriv['preparation_time'] + df_deriv['take_out_time_in_seconds']
    if 'total_amount' in df_deriv.columns and 'service_time_total' in df_deriv.columns:
        df_deriv['valor_por_segundo'] = df_deriv['total_amount'] / df_deriv['service_time_total'].replace(0, np.nan)
    print("Base carregada: merge_final.csv (fallback)")

df_deriv.columns = [c.strip().lower().replace(" ", "_") for c in df_deriv.columns]
print("Shape base derivada:", df_deriv.shape)


date_cols = [c for c in df_deriv.columns if c.endswith('_at') or 'date' in c]
for c in date_cols:
    df_deriv[c] = pd.to_datetime(df_deriv[c], errors='coerce')


dim_customer_cols = [c for c in [
    'customer_id','name','gender','email','phone','status','date_of_birth','idade'
] if c in df_deriv.columns]

if 'customer_id' in df_deriv.columns and dim_customer_cols:
    dim_customer = (
        df_deriv[dim_customer_cols]
        .drop_duplicates(subset=['customer_id'])
        .reset_index(drop=True)
    )
else:
    dim_customer = pd.DataFrame(columns=['customer_id'])
print("dim_customer:", dim_customer.shape)


dim_store_cols = [c for c in ['store_id','company_id'] if c in df_deriv.columns]
if 'store_id' in df_deriv.columns:
    dim_store = (
        df_deriv[dim_store_cols]
        .drop_duplicates(subset=['store_id'])
        .reset_index(drop=True)
    )
else:
    dim_store = pd.DataFrame(columns=['store_id'])
print("dim_store:", dim_store.shape)


calendar_sources = [c for c in ['created_at','updated_at','scheduled_at','send_at'] if c in df_deriv.columns]
if calendar_sources:

    cal_series = pd.concat([df_deriv[c].dropna().dt.normalize() for c in calendar_sources], axis=0).dropna().unique()
    dim_calendar = pd.DataFrame({'date': pd.to_datetime(cal_series)})
    dim_calendar['calendar_key'] = dim_calendar['date'].dt.strftime('%Y%m%d').astype(int)
    dim_calendar = dim_calendar.sort_values('date').reset_index(drop=True)
else:
    dim_calendar = pd.DataFrame(columns=['calendar_key','date'])
print("dim_calendar:", dim_calendar.shape)


fact = df_deriv.copy()

def add_calendar_key(f, src_col, key_name):
    if src_col in f.columns:
        f[key_name] = f[src_col].dt.strftime('%Y%m%d').astype(float)

        f[key_name] = f[key_name].astype('Int64')
    return f

for src, key in [('created_at','created_calendar_key'),
                 ('updated_at','updated_calendar_key'),
                 ('scheduled_at','scheduled_calendar_key'),
                 ('send_at','send_calendar_key')]:
    if src in fact.columns:
        fact = add_calendar_key(fact, src, key)


metric_cols = [c for c in ['total_amount','preparation_time','take_out_time_in_seconds','service_time_total','valor_por_segundo'] if c in fact.columns]
id_cols = [c for c in ['id','store_id','company_id','customer_id'] if c in fact.columns]
fk_calendar_cols = [c for c in fact.columns if c.endswith('_calendar_key')]


degenerate = [c for c in ['ticket_categoria','status'] if c in fact.columns]

fact_orders = fact[id_cols + fk_calendar_cols + metric_cols + degenerate].copy()


fact_integrated = fact_orders.copy()

if not dim_calendar.empty and 'created_calendar_key' in fact_integrated.columns:
    fact_integrated = fact_integrated.merge(
        dim_calendar[['calendar_key','date']].rename(columns={'calendar_key':'created_calendar_key','date':'created_date'}),
        on='created_calendar_key', how='left'
    )

if not dim_customer.empty and 'customer_id' in fact_integrated.columns:
    cust_ren = {c: f'customer__{c}' for c in dim_customer.columns if c not in ['customer_id']}
    fact_integrated = fact_integrated.merge(
        dim_customer.rename(columns=cust_ren),
        on='customer_id', how='left'
    )

if not dim_store.empty and 'store_id' in fact_integrated.columns:
    store_ren = {c: f'store__{c}' for c in dim_store.columns if c not in ['store_id']}
    fact_integrated = fact_integrated.merge(
        dim_store.rename(columns=store_ren),
        on='store_id', how='left'
    )

print("\nPr√©via ‚Äî dim_customer")
display(dim_customer.head(10))
print("\nPr√©via ‚Äî dim_store")
display(dim_store.head(10))
print("\nPr√©via ‚Äî dim_calendar")
display(dim_calendar.head(10))
print("\nPr√©via ‚Äî fact_orders (chaves e m√©tricas)")
display(fact_orders.head(10))
print("\nPr√©via ‚Äî fact_integrated (para explora√ß√£o)")
display(fact_integrated.head(10))

dim_customer.to_csv('dim_customer_inovatech.csv', index=False)
dim_store.to_csv('dim_store_inovatech.csv', index=False)
dim_calendar.to_csv('dim_calendar_inovatech.csv', index=False)
fact_orders.to_csv('fact_orders_inovatech.csv', index=False)
fact_integrated.to_csv('fact_orders_integrated_inovatech.csv', index=False)

print("\nArquivos gerados:")
print("- dim_customer_inovatech.csv")
print("- dim_store_inovatech.csv")
print("- dim_calendar_inovatech.csv")
print("- fact_orders_inovatech.csv")
print("- fact_orders_integrated_inovatech.csv")

if 'customer_id' in dim_customer.columns:
    print("\nCheck ‚Äî clientes √∫nicos na dimens√£o vs. fato:")
    print("dim_customer:", dim_customer['customer_id'].nunique(),
          "| fact_orders:", fact_orders['customer_id'].nunique() if 'customer_id' in fact_orders.columns else 'n/a')

if 'store_id' in dim_store.columns:
    print("Check ‚Äî lojas √∫nicas na dimens√£o vs. fato:")
    print("dim_store:", dim_store['store_id'].nunique(),
          "| fact_orders:", fact_orders['store_id'].nunique() if 'store_id' in fact_orders.columns else 'n/a')

# === ETAPA 6: FORMATAR OS DADOS ‚Äî InovaTech (com hotfix de duplicadas) ===
import pandas as pd
import numpy as np


try:
    df = pd.read_csv('fact_orders_integrated_inovatech.csv')
    origem = 'fact_orders_integrated_inovatech.csv'
except Exception:
    try:
        df = pd.read_csv('fact_orders_inovatech.csv')
        origem = 'fact_orders_inovatech.csv'
    except Exception:
        df = pd.read_csv('merge_inovatech_derived.csv')
        origem = 'merge_inovatech_derived.csv'

print(f" Base carregada: {origem} | shape={df.shape}")

df.columns = [c.strip().lower().replace(" ", "_") for c in df.columns]


date_cols = [c for c in df.columns if c.endswith('_at') or ('date' in c)]
for c in date_cols:
    df[c] = pd.to_datetime(df[c], errors='coerce')


numeric_candidates = [
    'total_amount','preparation_time','take_out_time_in_seconds',
    'service_time_total','valor_por_segundo','amount','price','value','count','quantity'
]
for c in df.columns:
    if any(tok in c for tok in numeric_candidates):
        if df[c].dtype == 'object':
            df[c] = (
                df[c].astype(str)
                     .str.replace('.', '', regex=False)
                     .str.replace(',', '.', regex=False)
            )
        df[c] = pd.to_numeric(df[c], errors='coerce')

if 'total_amount' in df.columns:
    df['total_amount'] = df['total_amount'].round(2)
for c in [x for x in df.select_dtypes(include='number').columns if x != 'total_amount']:
    df[c] = df[c].round(3)


id_cols = [c for c in df.columns if c == 'id' or c.endswith('_id') or c.endswith('_calendar_key')]
date_cols_fmt = [c for c in df.columns if (str(df[c].dtype).startswith('datetime64') or 'date' in c) and c not in id_cols]
metric_cols = list(df.select_dtypes(include='number').columns)
cat_cols = [c for c in df.columns if c not in id_cols + date_cols_fmt + metric_cols]

prefer_first = [c for c in ['id','company_id','store_id','customer_id',
                            'created_calendar_key','updated_calendar_key','scheduled_calendar_key','send_calendar_key'] if c in id_cols]
id_cols = prefer_first + [c for c in id_cols if c not in prefer_first]

ordered_cols = [c for c in (id_cols + date_cols_fmt + metric_cols + cat_cols) if c in df.columns]
df_final = df[ordered_cols].copy()


sort_keys = [c for c in ['updated_at','created_at','scheduled_at','send_at'] if c in df_final.columns]
if sort_keys:
    df_final = df_final.sort_values(by=sort_keys, ascending=[False]*len(sort_keys))
dups = df_final.columns[df_final.columns.duplicated()].tolist()
if dups:
    print(" Colunas duplicadas detectadas:", dups)
    def make_unique(cols):
        seen = {}
        new = []
        for c in cols:
            if c not in seen:
                seen[c] = 0
                new.append(c)
            else:
                seen[c] += 1
                new.append(f"{c}__dup{seen[c]}")
        return new
    df_final.columns = make_unique(df_final.columns)
    print(" Colunas renomeadas para garantir unicidade.")


dict_rows = []
for c in df_final.columns:
    col_obj = df_final[c]
    if isinstance(col_obj, pd.DataFrame):
        dtype_desc = "|".join(sorted(set([str(s.dtype) for _, s in col_obj.items()])))
        nulls = int(col_obj.isna().all(axis=1).sum())
    else:
        dtype_desc = str(col_obj.dtype)
        nulls = int(col_obj.isna().sum())
    grupo = ('ID' if c in id_cols else
             'DATA' if c in date_cols_fmt else
             'M√âTRICA' if c in metric_cols else
             'CATEG√ìRICA')
    dict_rows.append({'coluna': c, 'tipo': dtype_desc, 'grupo': grupo, 'nulos': nulls})
data_dict = pd.DataFrame(dict_rows).sort_values(['grupo','coluna'])
data_dict.to_csv('inovatech_data_dictionary.csv', index=False)

out_name = 'inovatech_prepared.csv'
df_final.to_csv(out_name, index=False)

print("\n Formata√ß√£o conclu√≠da.")
print(f"‚Üí Arquivo final: {out_name} | shape={df_final.shape}")
print("‚Üí Dicion√°rio de dados: inovatech_data_dictionary.csv")

display(df_final.head(10))
display(data_dict.head(15))